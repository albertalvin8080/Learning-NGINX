# rm -rf /var/cache/nginx -> debug purposes
proxy_cache_path /var/cache/nginx #  Location on the server's disk where cached responses will be stored.
    levels=1:2
    inactive=60m # minutes
    max_size=512m # megabytes
    keys_zone=myZone:20m; # megabytes

# Explanation:
# - `levels`   : defines the directory structure for storing cached files. The first level will have one subdirectory, and the second level will have two subdirectories within each first-level directory. This helps distribute cached files and improve performance.
# - `inactive` : sets the expiration time for cached responses.
# - `max_size` : defines the maximum total size of the cache storage. Once the cache reaches 512 megabytes (MB) in this case, Nginx will start removing the least recently used cached responses to free up space.
# - `keys_zone`: creates a *shared memory zone* named myZone that stores *metadata* about cached responses, such as the request URL, the corresponding backend server response, and timestamps. The size of this zone is limited to 20 MB in this case. This shared memory allows for faster lookups and management of cached data.

upstream backend {
    server springboot1:8080;
}

server {
    listen 80 default_server;
    return 444;
}

server {
    listen 80;
    server_name main.com;

    location / {
        proxy_pass http://backend;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $host;

        # This directive activates caching for the location block where it's placed.
        proxy_cache myZone;
        # This sets the minimum number of times a response must be accessed before it's considered "warm" and cached. 
        proxy_cache_min_uses 3;
        proxy_cache_methods GET;
        proxy_cache_valid 200 5m; # OK        | 5 minutes
        proxy_cache_valid 404 5m; # Not Found | 5 minutes

        # Header sent back to the browser with the status of the caching. Ex: HIT, MISS, BYPASS, etc.
        add_header X-Proxy-Cache $upstream_cache_status;

        # WARNING: there are some possibilities: 
        #  1 - If the Vary header receives a list of header names which contains different values for each user (like a Cookie header), the cached response will only be used for this user, because only they have the correct Cookie value.
        #  2 - If the Vary header receives a list of header names which have equal values for different users (like `Origin, Access-Control-Request-Method, Access-Control-Request-Headers`) the cached response will likely be used for more than one user.
        # proxy_ignore_headers Vary; # Used to change the behavior of caching. The backend server may and probably WILL interfere with this.
    }

    location /test1 {
        proxy_pass http://backend;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $host;

        proxy_cache myZone;
        proxy_cache_methods GET;
        proxy_cache_valid 200 5m;

        proxy_cache_bypass $cache_bypass; # See the `map` directive below this `server {}` block.
        # proxy_cache off; # Turns off the caching mechanism for this location.

        add_header X-Proxy-Cache $upstream_cache_status;
    }

    location /static/ {
        alias /app/resources/static/;
    }
}

# Map Cache-Control header values to bypass variable
map $http_cache_control $cache_bypass {
    "no-cache" 1;
    ""         0;
}
